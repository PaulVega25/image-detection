# API de DetecciÃ³n de Personas en ImÃ¡genes

Sistema de anÃ¡lisis de imÃ¡genes que detecta si una imagen contiene **al menos 1 persona**, diseÃ±ado para validar imÃ¡genes relacionadas con hechos delictivos.

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa:
- **Modelo de detecciÃ³n**: YOLOv5 pre-entrenado en COCO dataset para detectar personas
- **API REST**: FastAPI con endpoint para anÃ¡lisis de imÃ¡genes
- **ValidaciÃ³n**: Rechaza imÃ¡genes sin personas (perros, tazas, objetos, carros, etc.)
- **Dataset**: Validado con dataset de Roboflow "People Detection" (15,210+ imÃ¡genes)

## ğŸš€ InstalaciÃ³n

### 1. Instalar dependencias

```powershell
pip install -r requirements.txt
```

### 2. Generar el modelo

```powershell
python train_model.py
```

Este comando crearÃ¡ el archivo `person_detector_model.joblib` con el modelo entrenado.

## ğŸ’» Uso

### Iniciar el servidor

```powershell
python app.py
```

O usando uvicorn directamente:

```powershell
uvicorn app:app --reload --host 0.0.0.0 --port 8000
```

El servidor estarÃ¡ disponible en: `http://localhost:8000`

### DocumentaciÃ³n interactiva

Una vez iniciado el servidor, accede a:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## ğŸ“¡ Endpoints

### POST `/analizar-imagen`

Analiza una imagen y determina si contiene al menos 1 persona (valida hechos delictivos).

**Request:**
- MÃ©todo: `POST`
- Content-Type: `multipart/form-data`
- Body: Archivo de imagen (JPG, PNG, etc.)

**Response exitosa (imagen con persona):**

```json
{
  "valida": true,
  "numero_personas": 3,
  "mensaje": "Imagen vÃ¡lida: se detectaron 3 persona(s). Puede ser un hecho delictivo.",
  "confianza_promedio": 0.85,
  "dimensiones_imagen": {
    "ancho": 1920,
    "alto": 1080
  }
}
```

**Response imagen invÃ¡lida (sin personas):**

```json
{
  "valida": false,
  "numero_personas": 0,
  "mensaje": "Imagen no vÃ¡lida: no se detectaron personas. No es un hecho delictivo vÃ¡lido (puede ser objeto, animal, etc.).",
  "confianza_promedio": 0.0,
  "dimensiones_imagen": {
    "ancho": 800,
    "alto": 600
  }
}
```

### GET `/health`

Verifica el estado del servicio.

```json
{
  "status": "ok",
  "modelo_cargado": true
}
```

## ğŸ§ª Probar la API

### Con cURL:

```powershell
curl -X POST "http://localhost:8000/analizar-imagen" -F "imagen=@ruta/a/tu/imagen.jpg"
```

### Con Python:

```python
import requests

url = "http://localhost:8000/analizar-imagen"
files = {"imagen": open("imagen_prueba.jpg", "rb")}

response = requests.post(url, files=files)
print(response.json())
```

### Con la interfaz Swagger:

1. Navega a http://localhost:8000/docs
2. Click en el endpoint `/analizar-imagen`
3. Click en "Try it out"
4. Selecciona una imagen
5. Click en "Execute"

## ğŸ”§ ConfiguraciÃ³n del modelo

El modelo utiliza YOLOv5s con los siguientes parÃ¡metros ajustables en `train_model.py`:

```python
# Umbral de confianza para detecciones
umbral_confianza = 0.4  # Confianza mÃ­nima para considerar una detecciÃ³n

# Clases a detectar (solo personas)
self.model.classes = [0]  # 0 = person en COCO dataset
```

## ğŸ“Š Dataset

El modelo fue validado con el dataset de Roboflow "People Detection":
- **15,210 imÃ¡genes** de entrenamiento
- **100,000+ anotaciones** de personas
- MÃºltiples escenarios: calles, multitudes, cÃ¡maras de seguridad, etc.
- Fuente: https://universe.roboflow.com/leo-ueno/people-detection-o4rdr

## ğŸ“ Estructura del proyecto

```
modelo-imagen/
â”‚
â”œâ”€â”€ app.py                          # API FastAPI
â”œâ”€â”€ train_model.py                  # Script para generar el modelo
â”œâ”€â”€ person_detector_model.joblib    # Modelo guardado (generado)
â”œâ”€â”€ requirements.txt                # Dependencias
â””â”€â”€ README.md                       # DocumentaciÃ³n
```

## ğŸ¯ Casos de uso

**ImÃ¡genes vÃ¡lidas** (â‰¥ 1 persona - posibles hechos delictivos):
- âœ… Persona individual
- âœ… Grupos de personas
- âœ… Multitudes
- âœ… Eventos
- âœ… Cualquier escena con al menos una persona visible

**ImÃ¡genes invÃ¡lidas** (0 personas - NO son hechos delictivos):
- âŒ ImÃ¡genes de animales (perros, gatos)
- âŒ Objetos inanimados (tazas, mesas, carros)
- âŒ Paisajes sin personas
- âŒ Edificios vacÃ­os
- âŒ Naturaleza sin personas

## ğŸ› ï¸ TecnologÃ­as utilizadas

- **FastAPI**: Framework web moderno y rÃ¡pido
- **YOLOv5**: Estado del arte en detecciÃ³n de objetos
- **PyTorch**: Framework de deep learning
- **OpenCV**: Procesamiento de imÃ¡genes
- **Joblib**: SerializaciÃ³n del modelo
- **Pillow**: ManipulaciÃ³n de imÃ¡genes
- **Uvicorn**: Servidor ASGI
## ğŸ“ Notas importantes

1. El modelo YOLOv5 se descarga automÃ¡ticamente la primera vez (aprox. 14 MB)
2. YOLOv5 funciona muy bien en mÃºltiples escenarios y condiciones
3. La detecciÃ³n es robusta ante diferentes Ã¡ngulos, iluminaciÃ³n y poses
4. Para mejorar la detecciÃ³n en tu contexto especÃ­fico, ajusta el `umbral_confianza`
5. El primer anÃ¡lisis puede tardar mÃ¡s mientras se carga el modelo en memoria
## ğŸ”œ Mejoras futuras

- Fine-tuning de YOLOv5 con dataset especÃ­fico de hechos delictivos
- Implementar YOLOv8 o YOLOv9 para mayor precisiÃ³n
- AÃ±adir cache de resultados para optimizar respuestas
- Implementar procesamiento por lotes (batch)
- AÃ±adir autenticaciÃ³n y rate limiting
- Guardar logs de detecciones con timestamps
- API para reentrenamiento con nuevas imÃ¡genesor lotes
- AÃ±adir autenticaciÃ³n y rate limiting
- Guardar logs de detecciones

## ğŸ“ Soporte

Para reportar problemas o sugerencias, crea un issue en el repositorio.
